{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Dataset\n",
    "\n",
    "Toy Datasets: https://scikit-learn.org/stable/datasets/toy_dataset.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris_dict = load_iris()\n",
    "print(iris_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "[5.1 3.5 1.4 0.2]\n",
      "Target: ['setosa' 'versicolor' 'virginica']\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Features: {iris_dict['feature_names']}\")\n",
    "print(iris_dict['data'][0])\n",
    "\n",
    "print(f\"Target: {iris_dict['target_names']}\")\n",
    "print(iris_dict['target'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris_dict['data']\n",
    "y = iris_dict['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [5.7 2.5 5.  2. ] -> 2\n",
      "Test: [6.  2.9 4.5 1.5] -> 1\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train: {X_train[25]} -> {y_train[25]}\")\n",
    "print(f\"Test: {X_test[3]} -> {y_test[3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler() # subtract the mean and divide by standard deviation\n",
    "\n",
    "fit_scaler = scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "fit_scaler = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Raw] Min: 4.3; Max: 7.7\n",
      "[Scaled] Min: -1.86; Max: 2.24\n"
     ]
    }
   ],
   "source": [
    "print(f\"[Raw] Min: {min(X_train[:,0])}; Max: {max(X_train[:,0])}\")\n",
    "print(f\"[Scaled] Min: {min(X_train_scaled[:,0]):.2f}; Max: {max(X_train_scaled[:,0]):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic ML Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf = KNeighborsClassifier()\n",
    "clf = clf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled = scaler.transform(X_test) # only transform the test data (not fit)\n",
    "\n",
    "y_pred = clf.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# Fit the pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy =  pipeline.score(X_test, y_test) # notice that it handles the scaling of X_test\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with Grid Search and Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('classifier', KNeighborsClassifier(metric='manhattan'))])\n",
      "Parameters: {'classifier__metric': 'manhattan', 'classifier__n_neighbors': 5}\n",
      "Best Training Score: 0.9333333333333333\n",
      "Test Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# Define hyperparameters to search over\n",
    "params = {\n",
    "    'classifier__n_neighbors': [3, 5, 7],\n",
    "    'classifier__metric': ['euclidean','manhattan']\n",
    "}\n",
    "\n",
    "# Define GridSearch with Cross Validation\n",
    "grid_search = GridSearchCV(pipeline, params, cv=5, scoring='accuracy')\n",
    "\n",
    "# Find the best model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best Model: {grid_search.best_estimator_}\")\n",
    "print(f\"Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best Training Score: {grid_search.best_score_}\")\n",
    "\n",
    "# Predict using the pipeline\n",
    "y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
